{"cells":[{"cell_type":"markdown","id":"fe8d18d5","metadata":{"id":"fe8d18d5"},"source":["### Build and Train GRU model with Implementation of Hyperparameter Tuning"]},{"cell_type":"code","execution_count":1,"id":"bnnaYY0aw6Wf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27092,"status":"ok","timestamp":1758875689212,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"bnnaYY0aw6Wf","outputId":"edfc622d-c919-4b42-dad5-6d17bdb0379e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"171a02dd","metadata":{"executionInfo":{"elapsed":4213,"status":"ok","timestamp":1758875693419,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"171a02dd"},"outputs":[],"source":["# Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import GRU, Dense\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from sklearn.model_selection import KFold, train_test_split\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":3,"id":"909b3a84","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11158,"status":"ok","timestamp":1758875704580,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"909b3a84","outputId":"fd8be26b-4308-4681-8e5e-cee697f0f55c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test feature shape: (17631, 30, 66)\n","Test target shape: (17631,)\n"]}],"source":["# Load test features and labels\n","X = np.load('/content/drive/MyDrive/Infosys/MileStone3/rolling_window_sequences.npy')  # Replace with actual file path\n","metadata_test = pd.read_csv(\"/content/drive/MyDrive/Infosys/MileStone3/sequence_metadata_with_RUL.csv\")  # Replace with actual file path\n","y = metadata_test[\"RUL\"].values\n","print(\"Test feature shape:\", X.shape)\n","print(\"Test target shape:\", y.shape)"]},{"cell_type":"code","execution_count":5,"id":"c13f1ae0","metadata":{"executionInfo":{"elapsed":95,"status":"ok","timestamp":1758875719939,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"c13f1ae0"},"outputs":[],"source":["# Split the data into train and validation sets (assuming no separate train set given)\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":6,"id":"3b1cf4a6","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1758875722957,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"3b1cf4a6"},"outputs":[],"source":["# Define hyperparameters to tune\n","params = {\n","    'units': [32, 64],\n","    'batch_size': [16, 32],\n","    'epochs': 50,\n","    'learning_rate': [0.001, 0.0005]\n","}"]},{"cell_type":"code","execution_count":7,"id":"2e338927","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1758875724903,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"2e338927"},"outputs":[],"source":["# Set up 5-fold cross-validation\n","kfold = KFold(n_splits=5, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":8,"id":"a716b6b2","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1758875726804,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"a716b6b2"},"outputs":[],"source":["# Define a function to build the GRU model\n","def build_gru_model(units, learning_rate, input_shape):\n","    model = Sequential()\n","    model.add(GRU(units, input_shape=input_shape, return_sequences=False))\n","    model.add(Dense(1))  # Single output for regression (RUL)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n","    return model"]},{"cell_type":"code","execution_count":9,"id":"35a74dfb","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1758875728944,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"35a74dfb"},"outputs":[],"source":["# Define callbacks\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n","    ModelCheckpoint('best_gru_model.keras', monitor='val_loss', save_best_only=True),\n","    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=4, min_lr=1e-5, verbose=1)\n","]"]},{"cell_type":"code","execution_count":null,"id":"191a7ac3","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"191a7ac3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\n","Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\n","Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n"]}],"source":["best_val_loss = np.inf\n","best_model = None\n","best_params = None\n","\n","# Hyperparameter tuning with cross-validation\n","for units in params['units']:\n","    for batch_size in params['batch_size']:\n","        for learning_rate in params['learning_rate']:\n","            val_losses = []\n","            for train_idx, val_idx in kfold.split(X):\n","                X_train, X_val = X[train_idx], X[val_idx]\n","                y_train, y_val = y[train_idx], y[val_idx]\n","\n","                model = build_gru_model(units, learning_rate, input_shape=(X.shape[1], X.shape[2]))\n","\n","                history = model.fit(\n","                    X_train, y_train,\n","                    validation_data=(X_val, y_val),\n","                    epochs=params['epochs'],\n","                    batch_size=batch_size,\n","                    callbacks=callbacks,\n","                    verbose=0\n","                )\n","                val_loss = min(history.history['val_loss'])\n","                val_losses.append(val_loss)\n","\n","            avg_val_loss = np.mean(val_losses)\n","            if avg_val_loss \u003c best_val_loss:\n","                best_val_loss = avg_val_loss\n","                best_model = model\n","                best_params = (units, batch_size, learning_rate)\n"]},{"cell_type":"code","execution_count":null,"id":"568402d4","metadata":{"executionInfo":{"elapsed":42777,"status":"aborted","timestamp":1758875704674,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"568402d4"},"outputs":[],"source":["print(f\"Best validation loss: {best_val_loss}\")\n","print(f\"Best parameters: units={best_params[0]}, batch_size={best_params[1]}, learning_rate={best_params[2]}\")"]},{"cell_type":"code","execution_count":null,"id":"84da4bd9","metadata":{"executionInfo":{"elapsed":42798,"status":"aborted","timestamp":1758875704696,"user":{"displayName":"Veda Bhavishya Gudivaka","userId":"04960421174320275292"},"user_tz":-330},"id":"84da4bd9"},"outputs":[],"source":["# Save the best model\n","best_model.save('final_best_gru_model_cmapss.keras')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":5}